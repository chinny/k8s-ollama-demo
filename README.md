# Demo: Ollama and Llama3 in Kubernetes

## Overview

This repo contains the files used for my demo on how to serve an open-source large language model (LLM) in Kubernetes using a framework called Ollama.

## Problem

* Popular solutions like Google’s Gemini, OpenAI’s ChatGPT, and Microsoft’s Copilot (which also uses ChatGPT) are all closed-source LLMs.
* Cannot run these closed-source LLMs on your own hardware.
* If you want to build your own LLM from scratch, you will need to invest a lot of work and capital. 

## Solution

* You don’t have to start from scratch.
* Use an open-source LLMs like Google’s Gemma (which is based on Google Gemini) or Meta’s Llama.
* Run it on your own hardware.

## Reference

* Ollama Documentation [https://github.com/ollama/ollama/tree/main/docs]
* Meta Llama3 [https://llama.meta.com/llama3/]
* k3d [https://k3d.io]